{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Classifying Images with DeiT\n\r\nFollow the README.md at the DeiT repository for detailed information on how to classify images using DeiT, or for a quick test, first install the required packages:","metadata":{}},{"cell_type":"code","source":"!pip install torch torchvision timm pandas requests","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T18:49:17.600271Z","iopub.execute_input":"2024-10-19T18:49:17.601005Z","iopub.status.idle":"2024-10-19T18:49:31.313385Z","shell.execute_reply.started":"2024-10-19T18:49:17.600939Z","shell.execute_reply":"2024-10-19T18:49:31.312001Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0+cpu)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0+cpu)\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (1.0.9)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.32.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.3.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.2)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.25.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2024.8.30)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (21.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub->timm) (3.1.2)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install timm pandas requests","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T18:49:32.695660Z","iopub.execute_input":"2024-10-19T18:49:32.696166Z","iopub.status.idle":"2024-10-19T18:49:44.954481Z","shell.execute_reply.started":"2024-10-19T18:49:32.696118Z","shell.execute_reply":"2024-10-19T18:49:44.952615Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (1.0.9)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.32.3)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.4.0+cpu)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.19.0+cpu)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.2)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.25.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.5)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2024.8.30)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (21.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->timm) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.1.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (10.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub->timm) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.5)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from PIL import Image\nimport torch\nimport timm\nimport requests\nimport torchvision.transforms as transforms\nfrom timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n\nprint(torch.__version__)\n# should be 1.8.0\n\n\nmodel = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\nmodel.eval()\n\ntransform = transforms.Compose([\n    transforms.Resize(256, interpolation=3),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n])\n\nimg = Image.open(requests.get(\"https://raw.githubusercontent.com/pytorch/ios-demo-app/master/HelloWorld/HelloWorld/HelloWorld/image.png\", stream=True).raw)\nimg = transform(img)[None,]\nout = model(img)\nclsidx = torch.argmax(out)\nprint(clsidx.item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T18:49:52.965497Z","iopub.execute_input":"2024-10-19T18:49:52.965999Z","iopub.status.idle":"2024-10-19T18:50:06.006371Z","shell.execute_reply.started":"2024-10-19T18:49:52.965946Z","shell.execute_reply":"2024-10-19T18:50:06.004788Z"}},"outputs":[{"name":"stdout","text":"2.4.0+cpu\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://github.com/facebookresearch/deit/zipball/main\" to /root/.cache/torch/hub/main.zip\n/root/.cache/torch/hub/facebookresearch_deit_main/models.py:63: UserWarning: Overwriting deit_tiny_patch16_224 in registry with models.deit_tiny_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n  def deit_tiny_patch16_224(pretrained=False, **kwargs):\n/root/.cache/torch/hub/facebookresearch_deit_main/models.py:78: UserWarning: Overwriting deit_small_patch16_224 in registry with models.deit_small_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n  def deit_small_patch16_224(pretrained=False, **kwargs):\n/root/.cache/torch/hub/facebookresearch_deit_main/models.py:93: UserWarning: Overwriting deit_base_patch16_224 in registry with models.deit_base_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n  def deit_base_patch16_224(pretrained=False, **kwargs):\n/root/.cache/torch/hub/facebookresearch_deit_main/models.py:108: UserWarning: Overwriting deit_tiny_distilled_patch16_224 in registry with models.deit_tiny_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n  def deit_tiny_distilled_patch16_224(pretrained=False, **kwargs):\n/root/.cache/torch/hub/facebookresearch_deit_main/models.py:123: UserWarning: Overwriting deit_small_distilled_patch16_224 in registry with models.deit_small_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n  def deit_small_distilled_patch16_224(pretrained=False, **kwargs):\n/root/.cache/torch/hub/facebookresearch_deit_main/models.py:138: UserWarning: Overwriting deit_base_distilled_patch16_224 in registry with models.deit_base_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n  def deit_base_distilled_patch16_224(pretrained=False, **kwargs):\n/root/.cache/torch/hub/facebookresearch_deit_main/models.py:153: UserWarning: Overwriting deit_base_patch16_384 in registry with models.deit_base_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n  def deit_base_patch16_384(pretrained=False, **kwargs):\n/root/.cache/torch/hub/facebookresearch_deit_main/models.py:168: UserWarning: Overwriting deit_base_distilled_patch16_384 in registry with models.deit_base_distilled_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n  def deit_base_distilled_patch16_384(pretrained=False, **kwargs):\nDownloading: \"https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth\" to /root/.cache/torch/hub/checkpoints/deit_base_patch16_224-b5f2ef4d.pth\n100%|██████████| 330M/330M [00:02<00:00, 158MB/s]  \n","output_type":"stream"},{"name":"stdout","text":"269\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"The output should be 269, which, according to the ImageNet list of class index to labels file, maps to timber wolf, grey wolf, gray wolf, Canis lupus.\r\n\r\nNow that we have verified that we can use the DeiT model to classify images, let’s see how to modify the model so it can run on iOS and Android apps.","metadata":{}},{"cell_type":"markdown","source":"### Scripting DeiT\r\nTo use the model on mobile, we first need to script the model. See the Script and Optimize recipe for a quick overview. Run the code below to convert the DeiT model used in the previous step to the TorchScript format that can run on mobile.","metadata":{}},{"cell_type":"code","source":"model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\nmodel.eval()\nscripted_model = torch.jit.script(model)\nscripted_model.save(\"fbdeit_scripted.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T18:52:03.190910Z","iopub.execute_input":"2024-10-19T18:52:03.191455Z","iopub.status.idle":"2024-10-19T18:52:06.818729Z","shell.execute_reply.started":"2024-10-19T18:52:03.191402Z","shell.execute_reply":"2024-10-19T18:52:06.817576Z"}},"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/facebookresearch_deit_main\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### Quantizing DeiT","metadata":{}},{"cell_type":"markdown","source":"To reduce the trained model size significantly while keeping the inference accuracy about the same, quantization can be applied to the model. Thanks to the transformer model used in DeiT, we can easily apply dynamic-quantization to the model, because dynamic quantization works best for LSTM and transformer models (see here for more details).\r\n\r\nNow run the code below:","metadata":{}},{"cell_type":"code","source":"# Use 'x86' for server inference (the old 'fbgemm' is still available but 'x86' is the recommended default) and ``qnnpack`` for mobile inference.\nbackend = \"x86\" # replaced with ``qnnpack`` causing much worse inference speed for quantized model on this notebook\nmodel.qconfig = torch.quantization.get_default_qconfig(backend)\ntorch.backends.quantized.engine = backend\n\nquantized_model = torch.quantization.quantize_dynamic(model, qconfig_spec={torch.nn.Linear}, dtype=torch.qint8)\nscripted_quantized_model = torch.jit.script(quantized_model)\nscripted_quantized_model.save(\"fbdeit_scripted_quantized.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T18:54:53.778331Z","iopub.execute_input":"2024-10-19T18:54:53.778826Z","iopub.status.idle":"2024-10-19T18:54:57.559853Z","shell.execute_reply.started":"2024-10-19T18:54:53.778780Z","shell.execute_reply":"2024-10-19T18:54:57.558645Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/ao/quantization/observer.py:221: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"out = scripted_quantized_model(img)\nclsidx = torch.argmax(out)\nprint(clsidx.item())\n# The same output 269 should be printed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T18:56:42.346873Z","iopub.execute_input":"2024-10-19T18:56:42.347344Z","iopub.status.idle":"2024-10-19T18:56:42.893407Z","shell.execute_reply.started":"2024-10-19T18:56:42.347304Z","shell.execute_reply":"2024-10-19T18:56:42.891804Z"}},"outputs":[{"name":"stdout","text":"269\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"### Optimizing DeiT","metadata":{}},{"cell_type":"code","source":"from torch.utils.mobile_optimizer import optimize_for_mobile\noptimized_scripted_quantized_model = optimize_for_mobile(scripted_quantized_model)\noptimized_scripted_quantized_model.save(\"fbdeit_optimized_scripted_quantized.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T18:57:04.288274Z","iopub.execute_input":"2024-10-19T18:57:04.289175Z","iopub.status.idle":"2024-10-19T18:57:08.340747Z","shell.execute_reply.started":"2024-10-19T18:57:04.289121Z","shell.execute_reply":"2024-10-19T18:57:08.339463Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"out = optimized_scripted_quantized_model(img)\nclsidx = torch.argmax(out)\nprint(clsidx.item())\n# Again, the same output 269 should be printed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T18:57:14.019422Z","iopub.execute_input":"2024-10-19T18:57:14.019977Z","iopub.status.idle":"2024-10-19T18:57:14.303691Z","shell.execute_reply.started":"2024-10-19T18:57:14.019919Z","shell.execute_reply":"2024-10-19T18:57:14.302472Z"}},"outputs":[{"name":"stdout","text":"269\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### Using Lite Interpreter","metadata":{}},{"cell_type":"code","source":"optimized_scripted_quantized_model._save_for_lite_interpreter(\"fbdeit_optimized_scripted_quantized_lite.ptl\")\nptl = torch.jit.load(\"fbdeit_optimized_scripted_quantized_lite.ptl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T19:00:06.302473Z","iopub.execute_input":"2024-10-19T19:00:06.302978Z","iopub.status.idle":"2024-10-19T19:00:08.380321Z","shell.execute_reply.started":"2024-10-19T19:00:06.302929Z","shell.execute_reply":"2024-10-19T19:00:08.378922Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### Comparing Inference Speed","metadata":{}},{"cell_type":"code","source":"with torch.autograd.profiler.profile(use_cuda=False) as prof1:\n    out = model(img)\nwith torch.autograd.profiler.profile(use_cuda=False) as prof2:\n    out = scripted_model(img)\nwith torch.autograd.profiler.profile(use_cuda=False) as prof3:\n    out = scripted_quantized_model(img)\nwith torch.autograd.profiler.profile(use_cuda=False) as prof4:\n    out = optimized_scripted_quantized_model(img)\nwith torch.autograd.profiler.profile(use_cuda=False) as prof5:\n    out = ptl(img)\n\nprint(\"original model: {:.2f}ms\".format(prof1.self_cpu_time_total/1000))\nprint(\"scripted model: {:.2f}ms\".format(prof2.self_cpu_time_total/1000))\nprint(\"scripted & quantized model: {:.2f}ms\".format(prof3.self_cpu_time_total/1000))\nprint(\"scripted & quantized & optimized model: {:.2f}ms\".format(prof4.self_cpu_time_total/1000))\nprint(\"lite model: {:.2f}ms\".format(prof5.self_cpu_time_total/1000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T19:00:42.728514Z","iopub.execute_input":"2024-10-19T19:00:42.729632Z","iopub.status.idle":"2024-10-19T19:00:46.535234Z","shell.execute_reply.started":"2024-10-19T19:00:42.729577Z","shell.execute_reply":"2024-10-19T19:00:46.533629Z"}},"outputs":[{"name":"stdout","text":"original model: 406.15ms\nscripted model: 386.04ms\nscripted & quantized model: 314.78ms\nscripted & quantized & optimized model: 273.63ms\nlite model: 235.31ms\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({'Model': ['original model','scripted model', 'scripted & quantized model', 'scripted & quantized & optimized model', 'lite model']})\ndf = pd.concat([df, pd.DataFrame([\n    [\"{:.2f}ms\".format(prof1.self_cpu_time_total/1000), \"0%\"],\n    [\"{:.2f}ms\".format(prof2.self_cpu_time_total/1000),\n     \"{:.2f}%\".format((prof1.self_cpu_time_total-prof2.self_cpu_time_total)/prof1.self_cpu_time_total*100)],\n    [\"{:.2f}ms\".format(prof3.self_cpu_time_total/1000),\n     \"{:.2f}%\".format((prof1.self_cpu_time_total-prof3.self_cpu_time_total)/prof1.self_cpu_time_total*100)],\n    [\"{:.2f}ms\".format(prof4.self_cpu_time_total/1000),\n     \"{:.2f}%\".format((prof1.self_cpu_time_total-prof4.self_cpu_time_total)/prof1.self_cpu_time_total*100)],\n    [\"{:.2f}ms\".format(prof5.self_cpu_time_total/1000),\n     \"{:.2f}%\".format((prof1.self_cpu_time_total-prof5.self_cpu_time_total)/prof1.self_cpu_time_total*100)]],\n    columns=['Inference Time', 'Reduction'])], axis=1)\n\nprint(df)\n\n\"\"\"\n        Model                             Inference Time    Reduction\n0   original model                             1236.69ms           0%\n1   scripted model                             1226.72ms        0.81%\n2   scripted & quantized model                  593.19ms       52.03%\n3   scripted & quantized & optimized model      598.01ms       51.64%\n4   lite model                                  600.72ms       51.43%\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T19:02:36.239024Z","iopub.execute_input":"2024-10-19T19:02:36.239501Z","iopub.status.idle":"2024-10-19T19:02:36.904901Z","shell.execute_reply.started":"2024-10-19T19:02:36.239456Z","shell.execute_reply":"2024-10-19T19:02:36.903661Z"}},"outputs":[{"name":"stdout","text":"                                    Model Inference Time Reduction\n0                          original model       406.15ms        0%\n1                          scripted model       386.04ms     4.95%\n2              scripted & quantized model       314.78ms    22.50%\n3  scripted & quantized & optimized model       273.63ms    32.63%\n4                              lite model       235.31ms    42.06%\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'\\n        Model                             Inference Time    Reduction\\n0   original model                             1236.69ms           0%\\n1   scripted model                             1226.72ms        0.81%\\n2   scripted & quantized model                  593.19ms       52.03%\\n3   scripted & quantized & optimized model      598.01ms       51.64%\\n4   lite model                                  600.72ms       51.43%\\n'"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
