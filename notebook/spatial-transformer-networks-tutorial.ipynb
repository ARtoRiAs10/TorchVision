{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-10-19T12:39:03.154980Z","iopub.execute_input":"2024-10-19T12:39:03.155431Z","iopub.status.idle":"2024-10-19T12:39:04.643556Z","shell.execute_reply.started":"2024-10-19T12:39:03.155388Z","shell.execute_reply":"2024-10-19T12:39:04.642129Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# License: BSD\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nplt.ion()   # interactive mode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T12:39:04.645711Z","iopub.execute_input":"2024-10-19T12:39:04.646419Z","iopub.status.idle":"2024-10-19T12:39:09.842923Z","shell.execute_reply.started":"2024-10-19T12:39:04.646344Z","shell.execute_reply":"2024-10-19T12:39:09.841546Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<contextlib.ExitStack at 0x7bc2b0d0ee60>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from six.moves import urllib\nopener = urllib.request.build_opener()\nopener.addheaders = [('User-agent', 'Mozilla/5.0')]\nurllib.request.install_opener(opener)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Training dataset\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(root='.', train=True, download=True,\n                   transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])), batch_size=64, shuffle=True, num_workers=4)\n# Test dataset\ntest_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(root='.', train=False, transform=transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.1307,), (0.3081,))\n    ])), batch_size=64, shuffle=True, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T12:40:01.008863Z","iopub.execute_input":"2024-10-19T12:40:01.009480Z","iopub.status.idle":"2024-10-19T12:40:03.220542Z","shell.execute_reply.started":"2024-10-19T12:40:01.009431Z","shell.execute_reply":"2024-10-19T12:40:03.218846Z"}},"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\n<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 48486208.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\n<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 1767346.46it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Failed to download (trying next):\n<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1648877/1648877 [00:00<00:00, 12231380.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\n<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 2280408.04it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### Depicting spatial transformer networks\r\nSpatial transformer networks boils down to three main components :\r\n\r\nThe localization network is a regular CNN which regresses the transformation parameters. The transformation is never learned explicitly from this dataset, instead the network learns automatically the spatial transformations that enhances the global accuracy.\r\n\r\nThe grid generator generates a grid of coordinates in the input image corresponding to each pixel from the output image.\r\n\r\nThe sampler uses the parameters of the transformation and applies it to the input image.","metadata":{}},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n        # Spatial transformer localization-network\n        self.localization = nn.Sequential(\n            nn.Conv2d(1, 8, kernel_size=7),\n            nn.MaxPool2d(2, stride=2),\n            nn.ReLU(True),\n            nn.Conv2d(8, 10, kernel_size=5),\n            nn.MaxPool2d(2, stride=2),\n            nn.ReLU(True)\n        )\n\n        # Regressor for the 3 * 2 affine matrix\n        self.fc_loc = nn.Sequential(\n            nn.Linear(10 * 3 * 3, 32),\n            nn.ReLU(True),\n            nn.Linear(32, 3 * 2)\n        )\n\n        # Initialize the weights/bias with identity transformation\n        self.fc_loc[2].weight.data.zero_()\n        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n\n    # Spatial transformer network forward function\n    def stn(self, x):\n        xs = self.localization(x)\n        xs = xs.view(-1, 10 * 3 * 3)\n        theta = self.fc_loc(xs)\n        theta = theta.view(-1, 2, 3)\n\n        grid = F.affine_grid(theta, x.size())\n        x = F.grid_sample(x, grid)\n\n        return x\n\n    def forward(self, x):\n        # transform the input\n        x = self.stn(x)\n\n        # Perform the usual forward pass\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n\n\nmodel = Net().to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T12:56:20.866599Z","iopub.execute_input":"2024-10-19T12:56:20.867869Z","iopub.status.idle":"2024-10-19T12:56:20.910567Z","shell.execute_reply.started":"2024-10-19T12:56:20.867812Z","shell.execute_reply":"2024-10-19T12:56:20.909284Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### Training the model","metadata":{}},{"cell_type":"markdown","source":"Now, let’s use the SGD algorithm to train the model. The network is learning the classification task in a supervised way. In the same time the model is learning STN automatically in an end-to-end fashion.","metadata":{}},{"cell_type":"code","source":"optimizer = optim.SGD(model.parameters(), lr=0.01)\n\n\ndef train(epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 500 == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n#\n# A simple test procedure to measure the STN performances on MNIST.\n#\n\n\ndef test():\n    with torch.no_grad():\n        model.eval()\n        test_loss = 0\n        correct = 0\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n\n            # sum up batch loss\n            test_loss += F.nll_loss(output, target, size_average=False).item()\n            # get the index of the max log-probability\n            pred = output.max(1, keepdim=True)[1]\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n        test_loss /= len(test_loader.dataset)\n        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n              .format(test_loss, correct, len(test_loader.dataset),\n                      100. * correct / len(test_loader.dataset)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T13:09:06.440729Z","iopub.execute_input":"2024-10-19T13:09:06.441201Z","iopub.status.idle":"2024-10-19T13:09:06.453044Z","shell.execute_reply.started":"2024-10-19T13:09:06.441158Z","shell.execute_reply":"2024-10-19T13:09:06.451702Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### Visualizing the STN results\r\n","metadata":{}},{"cell_type":"code","source":"def convert_image_np(inp):\n    \"\"\"Convert a Tensor to numpy image.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    return inp\n\n# We want to visualize the output of the spatial transformers layer\n# after the training, we visualize a batch of input images and\n# the corresponding transformed batch using STN.\n\n\ndef visualize_stn():\n    with torch.no_grad():\n        # Get a batch of training data\n        data = next(iter(test_loader))[0].to(device)\n\n        input_tensor = data.cpu()\n        transformed_input_tensor = model.stn(data).cpu()\n\n        in_grid = convert_image_np(\n            torchvision.utils.make_grid(input_tensor))\n\n        out_grid = convert_image_np(\n            torchvision.utils.make_grid(transformed_input_tensor))\n\n        # Plot the results side-by-side\n        f, axarr = plt.subplots(1, 2)\n        axarr[0].imshow(in_grid)\n        axarr[0].set_title('Dataset Images')\n\n        axarr[1].imshow(out_grid)\n        axarr[1].set_title('Transformed Images')\n\nfor epoch in range(1, 20 + 1):\n    train(epoch)\n    test()\n\n# Visualize the STN transformation on some input batch\nvisualize_stn()\n\nplt.ioff()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T13:50:59.032110Z","iopub.execute_input":"2024-10-19T13:50:59.032558Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4434: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4373: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.395264\nTrain Epoch: 1 [32000/60000 (53%)]\tLoss: 0.616215\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n  warnings.warn(warning.format(ret))\n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.2167, Accuracy: 9421/10000 (94%)\n\nTrain Epoch: 2 [0/60000 (0%)]\tLoss: 0.437003\nTrain Epoch: 2 [32000/60000 (53%)]\tLoss: 0.538633\n\nTest set: Average loss: 0.1398, Accuracy: 9595/10000 (96%)\n\nTrain Epoch: 3 [0/60000 (0%)]\tLoss: 0.380890\nTrain Epoch: 3 [32000/60000 (53%)]\tLoss: 0.254402\n\nTest set: Average loss: 0.1121, Accuracy: 9667/10000 (97%)\n\nTrain Epoch: 4 [0/60000 (0%)]\tLoss: 0.180495\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
